{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0]]])\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import heapq\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# code based loosely on the following 2 projects\n",
    "# https://github.com/budzianowski/PyTorch-Beam-Search-Decoding/blob/master/decode_beam.py\n",
    "# https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/DecoderRNN.py\n",
    "\n",
    "\n",
    "class BeamDecoder:          \n",
    "    def decode(self, utt_embeds, beam_width=5):\n",
    "        output = []\n",
    "        for idx, utt_embeds in enumerate(utt_embeds): \n",
    "            # set up decoding, init queue and set start variables\n",
    "            device = utt_embeds.device\n",
    "            cur_utt = utt_embeds[0]\n",
    "            hx = torch.zeros([self.h_size], device=device)\n",
    "            cx = torch.zeros([self.h_size], device=device)\n",
    "            \n",
    "            # add first point to states\n",
    "            first_node = SimpleNamespace(path=[self.start_tok], log_prob=0, h=hx, c=cx)\n",
    "            current_states = [first_node]    \n",
    "            \n",
    "            # do beam search\n",
    "            for utt_num in range(len(utt_embeds)):\n",
    "                utt = utt_embeds[utt_num]\n",
    "                next_states = []\n",
    "                for node in current_states:\n",
    "                    prev_label =  torch.LongTensor([node.path[-1]]).to(device)\n",
    "                    \n",
    "                    # run through next cell and select top k probabilities\n",
    "                    y, hx, cx = self.step(embed=utt, label=prev_label, hx=node.h, cx=node.c)\n",
    "                    y_log_probs = F.log_softmax(y, dim=-1)\n",
    "                    log_prob, indexes = torch.topk(y_log_probs, beam_width)\n",
    "                    \n",
    "                    # add all new states to next search space\n",
    "                    for prob, ind in zip(log_prob, indexes):\n",
    "                        path = node.path.copy() + [ind.item()]\n",
    "                        prob = node.log_prob + prob\n",
    "                        next_node = SimpleNamespace(path=path, log_prob=prob, h=hx, c=cx)\n",
    "                        next_states.append(next_node)\n",
    "                    \n",
    "                # prune states to the best k states\n",
    "                next_states.sort(key=lambda x: x.log_prob, reverse=True)\n",
    "                next_states = next_states[:beam_width]\n",
    "                current_states = next_states\n",
    "            \n",
    "            solution = current_states[0]\n",
    "            output.append(solution.path[1:])\n",
    "        output = torch.LongTensor(output).to(device) #[B, N]\n",
    "        output = F.one_hot(output, num_classes=self.num_class).float() #[B, N, C]\n",
    "        return output\n",
    "    \n",
    "class DecoderRNN(nn.Module, BeamDecoder):\n",
    "    def __init__(self, cell_type, num_class, embed_size=10, h_size=768, rnn_h_size=300, dropout=0.0):\n",
    "        '''RNN decoder which when given a sequence of vectors, outputs sequence of decisions'''\n",
    "        super().__init__()\n",
    "        \n",
    "        #make embeddings for labels\n",
    "        self.embedding = nn.Embedding(num_class+1, embed_size) # [-1] is start token\n",
    "        self.start_tok = num_class\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        #make RNN decoder\n",
    "        if cell_type.lower() == 'lstm':  self.rnn_cell = nn.LSTM\n",
    "        elif cell_type.lower() == 'gru': self.rnn_cell = nn.GRU\n",
    "        else: raise ValueError(\"unsupported RNN type\")\n",
    "        \n",
    "        rnn_input_size = embed_size+h_size #concatentation to effectively have 2 inputs (Wy + Wh)\n",
    "        self.rnn = self.rnn_cell(rnn_input_size, rnn_h_size, bidirectional=False, dropout=dropout, batch_first=True)\n",
    "        self.h_size = rnn_h_size\n",
    "\n",
    "        #output classifier\n",
    "        self.classifier = nn.Linear(rnn_h_size, num_class)\n",
    "\n",
    "    def forward(self, utt_embeds, labels):\n",
    "        \"\"\"teacher forcing training\"\"\"\n",
    "        labels = torch.roll(labels, 1, -1)    #roll labels to use previous\n",
    "        labels[:, 0] = self.start_tok         #set start token\n",
    "        labels[labels==-100] = self.start_tok #pad all labels with -100\n",
    "        label_embed = self.embedding(labels)  # [B, N]->[B, N, D_e]\n",
    "        \n",
    "        rnn_inputs  = torch.cat((utt_embeds, label_embed), dim=-1)\n",
    "        output, (hn, cn) = self.rnn(rnn_inputs)\n",
    "        y = self.classifier(output)         # [B, N, D]->[B, N, 43]\n",
    "        return y\n",
    "\n",
    "    def step(self, embed, label, hx=None, cx=None):\n",
    "        \"\"\"steps a single input through a RNN cell. label.shape = [1]\n",
    "        embed.shape = cx.shape = hx.shape = [100]\"\"\"\n",
    "        \n",
    "        embed       = embed.view(1,1,-1)\n",
    "        label_embed = self.embedding(label).view(1,1,-1)\n",
    "        rnn_input   = torch.cat((embed, label_embed), dim=-1)  # [1,1,E]\n",
    "        output, (hx, cx) = self.rnn(rnn_input, (hx.view(1,1,-1), cx.view(1,1,-1)))\n",
    "        y = self.classifier(output)\n",
    "        return y.view(-1), hx.view(-1), cx.view(-1)\n",
    "\n",
    "\n",
    "model = DecoderRNN('lstm', 5, 10, 100, 50, 0)\n",
    "a = torch.rand((4,10,100))\n",
    "b = torch.randint(0, 5, (4,10))\n",
    "#print(a.shape)\n",
    "#print(b.shape)\n",
    "#model(a, b)\n",
    "y = model.decode(a)\n",
    "print(y)\n",
    "#embed = torch.rand((100))\n",
    "#label = torch.LongTensor([1])\n",
    "#h, c = torch.zeros(50), torch.zeros(50)\n",
    "#print(h.shape)\n",
    "#model.step(embed, label, h, c)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bool\n",
      "torch.Size([3, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "a = torch.rand(9, 768)\n",
    "b = torch.rand(6, 768)\n",
    "c = torch.rand(8, 768)\n",
    "\n",
    "x = pad_sequence([a,b,c], batch_first=True, padding_value=0.0)\n",
    "mask = torch.all((x!=0), dim=-1)\n",
    "print(mask.dtype)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decode(target_tensor, decoder_hiddens, encoder_outputs=None):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "\n",
    "    beam_width = 10\n",
    "    topk = 1  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "\n",
    "    # decoding goes sentence by sentence\n",
    "    for idx in range(target_tensor.size(0)):\n",
    "        if isinstance(decoder_hiddens, tuple):  # LSTM case\n",
    "            decoder_hidden = (decoder_hiddens[0][:,idx, :].unsqueeze(0),decoder_hiddens[1][:,idx, :].unsqueeze(0))\n",
    "        else:\n",
    "            decoder_hidden = decoder_hiddens[:, idx, :].unsqueeze(0)\n",
    "        encoder_output = encoder_outputs[:,idx, :].unsqueeze(1)\n",
    "\n",
    "        # Start with the start of the sentence token\n",
    "        decoder_input = torch.LongTensor([[SOS_token]], device=device)\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "\n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            print(decoder_input.shape, decoder_hidden.shape)\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                # increase qsize\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 50\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, cell_type, dropout=0.1):\n",
    "        '''\n",
    "        Illustrative decoder\n",
    "        '''\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size,\n",
    "                                      embedding_dim=embedding_size,\n",
    "                                      )\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, bidirectional=False, dropout=dropout, batch_first=False)\n",
    "        self.dropout_rate = dropout\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, not_used):\n",
    "        embedded = self.embedding(input).transpose(0, 1)  # [B,1] -> [ 1, B, D]\n",
    "        embedded = F.dropout(embedded, self.dropout_rate)\n",
    "\n",
    "        output = embedded\n",
    "\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        out = self.out(output.squeeze(0))\n",
    "        output = F.log_softmax(out, dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "\n",
    "\n",
    "\n",
    "def beam_decode(target_tensor, decoder_hiddens, encoder_outputs=None):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "\n",
    "    beam_width = 10\n",
    "    topk = 1  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "\n",
    "    # decoding goes sentence by sentence\n",
    "    for idx in range(target_tensor.size(0)):\n",
    "        if isinstance(decoder_hiddens, tuple):  # LSTM case\n",
    "            decoder_hidden = (decoder_hiddens[0][:,idx, :].unsqueeze(0),decoder_hiddens[1][:,idx, :].unsqueeze(0))\n",
    "        else:\n",
    "            decoder_hidden = decoder_hiddens[:, idx, :].unsqueeze(0)\n",
    "        encoder_output = encoder_outputs[:,idx, :].unsqueeze(1)\n",
    "\n",
    "        # Start with the start of the sentence token\n",
    "        decoder_input = torch.LongTensor([[SOS_token]], device=device)\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "\n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            print(decoder_input.shape, decoder_hidden.shape)\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "\n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "        utterances = []\n",
    "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "            utterance = []\n",
    "            utterance.append(n.wordid)\n",
    "            # back trace\n",
    "            while n.prevNode != None:\n",
    "                n = n.prevNode\n",
    "                utterance.append(n.wordid)\n",
    "\n",
    "            utterance = utterance[::-1]\n",
    "            utterances.append(utterance)\n",
    "\n",
    "        decoded_batch.append(utterances)\n",
    "\n",
    "    return decoded_batch\n",
    "\n",
    "decoder = DecoderRNN(100, 100, 100, 'lstm', dropout=0)\n",
    "\n",
    "a = torch.randint(0, 5, (4,10))\n",
    "b = torch.randint(0, 5, (1, 4, 100))\n",
    "c = torch.rand((10, 4, 100))\n",
    "beam_decode(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
